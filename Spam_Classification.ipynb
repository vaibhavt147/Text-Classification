{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam_Classification",
      "provenance": [],
      "mount_file_id": "1iaiSfQz4M9lXkfVFnCXBfd5Efo-BVe2A",
      "authorship_tag": "ABX9TyNIJ8IoK5TFRLFB64ECA1Dh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavt147/Text-Classification/blob/master/Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7R_vVl_r9FO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f2d215e7-5f61-4d12-a3d0-d8493f36e2be"
      },
      "source": [
        "import sys\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import sklearn\n",
        "import pandas\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DJ9FRReq-aI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"/content/drive/My Drive/Datasets/SMSSpamCollection\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk4uAYX1r7vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_table(file_name, header=None, encoding='utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQGuV5GVsL6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a7c00f85-8ee9-4abe-e031-ac9787de665f"
      },
      "source": [
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       5572 non-null   object\n",
            " 1   1       5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n",
            "None\n",
            "      0                                                  1\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUwtLrOEsSYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "14e28bde-3c5d-4154-a61f-1383bee8c935"
      },
      "source": [
        "classes = df[0]\n",
        "print(classes.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ham     4825\n",
            "spam     747\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAcofnB_s429",
        "colab_type": "text"
      },
      "source": [
        "**2. Preprocessing the Data**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In the following cells, we will convert our class labels to binary values using the LabelEncoder from sklearn, replace email addresses, URLs, phone numbers, and other symbols by using regular expressions, remove stop words, and extract word stems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jit37DWas0Cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29b200f6-4d35-4a98-ece2-22effc3ae88f"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(classes)\n",
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ca4nDTZt4D2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c8a3bf11-4ce7-4352-f06b-ffc928e41450"
      },
      "source": [
        "texts = df[1]\n",
        "print(texts[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Go until jurong point, crazy.. Available only ...\n",
            "1                        Ok lar... Joking wif u oni...\n",
            "2    Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3    U dun say so early hor... U c already then say...\n",
            "4    Nah I don't think he goes to usf, he lives aro...\n",
            "Name: 1, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFM-tjo5uVUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using regular expressions to replace email addresses, URLs, phone numbers, other numbers\n",
        "\n",
        "# Replace email addresses with 'email'\n",
        "processed = texts.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
        "                                 'emailaddress')\n",
        "\n",
        "# Replace URLs with 'webaddress'\n",
        "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
        "                                  'webaddress')\n",
        "\n",
        "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
        "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
        "    \n",
        "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
        "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
        "                                  'phonenumbr')\n",
        "    \n",
        "# Replace numbers with 'numbr'\n",
        "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYketVAiulHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove punctuation\n",
        "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "\n",
        "# Replace whitespace between terms with a single space\n",
        "processed = processed.str.replace(r'\\s+', ' ')\n",
        "\n",
        "# Remove leading and trailing whitespace\n",
        "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4BOLyMMuwgC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8d512c4a-7704-421d-ba53-c2debf408532"
      },
      "source": [
        "# changing words to lower case - Hello, HELLO, hello are all the same word\n",
        "processed = processed.str.lower()\n",
        "print(processed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0       go until jurong point crazy available only in ...\n",
            "1                                 ok lar joking wif u oni\n",
            "2       free entry in numbr a wkly comp to win fa cup ...\n",
            "3             u dun say so early hor u c already then say\n",
            "4       nah i don t think he goes to usf he lives arou...\n",
            "                              ...                        \n",
            "5567    this is the numbrnd time we have tried numbr c...\n",
            "5568                  will ü b going to esplanade fr home\n",
            "5569    pity was in mood for that so any other suggest...\n",
            "5570    the guy did some bitching but i acted like i d...\n",
            "5571                            rofl its true to its name\n",
            "Name: 1, Length: 5572, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t1sSSIKu4Ju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# remove stop words from text messages\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    term for term in x.split() if term not in stop_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaOV8rQGu-Bc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove word stems using a Porter stemmer\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    ps.stem(term) for term in x.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I998j8GNvqPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# create bag-of-words\n",
        "all_words = []\n",
        "\n",
        "for message in processed:\n",
        "    words = word_tokenize(message)\n",
        "    for w in words:\n",
        "        all_words.append(w)\n",
        "        \n",
        "all_words = nltk.FreqDist(all_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAYZKuHFvuWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a84fd45a-fba6-4c8b-bf4e-151cd4066b60"
      },
      "source": [
        "# print the total number of words and the 15 most common words\n",
        "print('Number of words: {}'.format(len(all_words)))\n",
        "print('Most common words: {}'.format(all_words.most_common(15)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words: 6579\n",
            "Most common words: [('numbr', 2648), ('u', 1207), ('call', 674), ('go', 456), ('get', 451), ('ur', 391), ('gt', 318), ('lt', 316), ('come', 304), ('moneysymbnumbr', 303), ('ok', 293), ('free', 284), ('day', 276), ('know', 275), ('love', 266)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0bbuSSFv3or",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the 1500 most common words as features\n",
        "word_features = list(all_words.keys())[:1500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhmT2Ph5v5V9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "bd4f54af-b09b-4490-9904-550443a635d9"
      },
      "source": [
        "# The find_features function will determine which of the 1500 word features are contained in the review\n",
        "def find_features(message):\n",
        "    words = word_tokenize(message)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features[word] = (word in words)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Lets see an example!\n",
        "features = find_features(processed[0])\n",
        "for key, value in features.items():\n",
        "    if value == True:\n",
        "        print (key)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n",
            "jurong\n",
            "point\n",
            "crazi\n",
            "avail\n",
            "bugi\n",
            "n\n",
            "great\n",
            "world\n",
            "la\n",
            "e\n",
            "buffet\n",
            "cine\n",
            "got\n",
            "amor\n",
            "wat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSbrh5dov7mB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now lets do it for all the messages\n",
        "messages = list(zip(processed, y))\n",
        "\n",
        "# define a seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed = seed\n",
        "np.random.shuffle(messages)\n",
        "\n",
        "# call find_features function for each SMS message\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03twyd-6wC_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6bac9857-861a-4efa-bd9f-b83009fdc6e0"
      },
      "source": [
        "# we can split the featuresets into training and testing datasets using sklearn\n",
        "from sklearn import model_selection\n",
        "\n",
        "# split the data into training and testing datasets\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)\n",
        "\n",
        "print(len(training))\n",
        "print(len(testing))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4179\n",
            "1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MITWKlfkwtp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3979a88-a3b8-4fb0-be43-59f9b87681fc"
      },
      "source": [
        "# We can use sklearn algorithms in NLTK\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
        "\n",
        "# train the model on the training data\n",
        "model.train(training)\n",
        "\n",
        "# and test on the testing dataset!\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niqv_-hdw9zv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5926d25f-ab99-4ab4-b654-72321e6436a3"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "# Define models to train\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = zip(names, classifiers)\n",
        "\n",
        "for name, model in models:\n",
        "    nltk_model = SklearnClassifier(model)\n",
        "    nltk_model.train(training)\n",
        "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "    print(\"{} Accuracy: {}\".format(name, accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K Nearest Neighbors Accuracy: 93.61091170136396\n",
            "Decision Tree Accuracy: 97.84637473079684\n",
            "Random Forest Accuracy: 98.49246231155779\n",
            "Logistic Regression Accuracy: 98.77961234745155\n",
            "SGD Classifier Accuracy: 98.49246231155779\n",
            "Naive Bayes Accuracy: 98.63603732950466\n",
            "SVM Linear Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJbk7tvxDYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a170b5f-188f-44b8-e989-74ad41a2d28e"
      },
      "source": [
        "# Ensemble methods - Voting classifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
        "         \"Naive Bayes\", \"SVM Linear\"]\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    LogisticRegression(),\n",
        "    SGDClassifier(max_iter = 100),\n",
        "    MultinomialNB(),\n",
        "    SVC(kernel = 'linear')\n",
        "]\n",
        "\n",
        "models = list(zip(names, classifiers))\n",
        "\n",
        "nltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\n",
        "nltk_ensemble.train(training)\n",
        "accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
        "print(\"Voting Classifier: Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting Classifier: Accuracy: 98.63603732950466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lky968r-xJ5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class label prediction for testing set\n",
        "txt_features, labels = zip(*testing)\n",
        "\n",
        "prediction = nltk_ensemble.classify_many(txt_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60f4MJjxL1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print a confusion matrix and a classification report\n",
        "print(classification_report(labels, prediction))\n",
        "\n",
        "pd.DataFrame(\n",
        "    confusion_matrix(labels, prediction),\n",
        "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
        "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZWN8eAaxQfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}